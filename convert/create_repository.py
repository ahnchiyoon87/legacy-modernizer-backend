from collections import defaultdict
import logging
import textwrap
import json
from understand.neo4j_connection import Neo4jConnection
from util.exception import ConvertingError
from util.utility_tool import convert_to_camel_case, convert_to_pascal_case, save_file, build_rule_based_path, build_variable_index, extract_used_variable_nodes
from util.rule_loader import RuleLoader


MAX_TOKENS = 1000  # LLM ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ë‹¹ ìµœëŒ€ í† í° ìˆ˜


# ----- Repository ìƒì„± ê´€ë¦¬ í´ë˜ìŠ¤ -----
class RepositoryGenerator:
    """
    ë ˆê±°ì‹œ SQL ì¿¼ë¦¬(DML)ë¥¼ ë¶„ì„í•˜ì—¬ Spring Data JPA Repository ì¸í„°í˜ì´ìŠ¤ë¥¼ ìë™ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤
    1ë‹¨ê³„: Repository Skeleton (ê¸°ë³¸ í‹€) ìƒì„±
    2ë‹¨ê³„: DMLì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ JPA ë©”ì„œë“œ ìƒì„±
    3ë‹¨ê³„: Skeletonê³¼ ë©”ì„œë“œ ë³‘í•©
    """
    __slots__ = ('project_name', 'user_id', 'api_key', 'locale', 'save_path', 
                 'global_vars', 'var_index', 'all_used_query_methods', 
                 'all_sequence_methods', 'aggregated_query_methods', 'rule_loader')

    def __init__(self, project_name: str, user_id: str, api_key: str, locale: str = 'ko', target_lang: str = 'java'):
        """
        RepositoryGenerator ì´ˆê¸°í™”
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            user_id: ì‚¬ìš©ì ì‹ë³„ì
            api_key: LLM API í‚¤
            locale: ì–¸ì–´ ì„¤ì • (ê¸°ë³¸ê°’: 'ko')
            target_lang: íƒ€ê²Ÿ ì–¸ì–´ (ê¸°ë³¸ê°’: 'java')
        """
        self.project_name = project_name
        self.user_id = user_id
        self.api_key = api_key
        self.locale = locale
        self.rule_loader = RuleLoader(target_lang=target_lang)
        self.save_path = build_rule_based_path(project_name, user_id, target_lang, 'repository')

    async def generate(self) -> tuple:
        """
        Repository ì¸í„°í˜ì´ìŠ¤ ìƒì„±ì˜ ë©”ì¸ ì§„ì…ì 
        1. Skeleton ìƒì„± (í…Œì´ë¸”ë‹¹ 1íšŒ)
        2. DMLì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ì„œë“œ ìƒì„±
        3. Skeletonê³¼ ë©”ì„œë“œ ë³‘í•©
        
        Returns:
            tuple: (used_query_methods, global_variables, sequence_methods, repository_list)
        """
        logging.info("Repository Interface ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        connection = Neo4jConnection()
        
        logging.info("\n" + "="*80)
        logging.info("ğŸ—„ï¸  STEP 2: Repository Interface ìƒì„± ì‹œì‘")
        logging.info("="*80)
        
        try:
            # Neo4jì—ì„œ DML ë…¸ë“œ ë° ë³€ìˆ˜ ì •ë³´ ì¡°íšŒ
            logging.info("ğŸ“Š Neo4jì—ì„œ DML ë…¸ë“œ ë° ë³€ìˆ˜ ì¡°íšŒ ì¤‘...")
            table_dml_results, var_results = await connection.execute_queries([
                f"""MATCH (n {{user_id: '{self.user_id}', project_name: '{self.project_name}'}})
                    WHERE n:SELECT OR n:UPDATE OR n:DELETE OR n:MERGE
                    AND NOT EXISTS {{ MATCH (p)-[:PARENT_OF]->(n) WHERE p:SELECT OR p:UPDATE OR p:DELETE OR p:MERGE }}
                    OPTIONAL MATCH (n)-[:FROM|WRITES]->(t:Table {{user_id: '{self.user_id}', project_name: '{self.project_name}'}})
                    WITH t, collect(n) as dml_nodes WHERE t IS NOT NULL
                    RETURN t, dml_nodes""",
                f"""MATCH (v:Variable {{user_id: '{self.user_id}', project_name: '{self.project_name}'}})
                    RETURN v, v.scope as scope"""
            ])

            # ë³€ìˆ˜ë¥¼ Local/Globalë¡œ ë¶„ë¦¬
            local_vars = []
            self.global_vars = []
            for var in var_results:
                if var['scope'] == 'Global':
                    v_node = var['v']
                    self.global_vars.append({
                        'name': v_node['name'],
                        'type': v_node.get('type', 'Unknown'),
                        'role': v_node.get('role', ''),
                        'scope': 'Global',
                        'value': v_node.get('value', '')
                    })
                else:
                    local_vars.append(var)
            
            # ë³€ìˆ˜ ì¸ë±ìŠ¤ ìƒì„±
            self.var_index = build_variable_index(local_vars)
            
            # ê²°ê³¼ ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™”
            self.all_used_query_methods = {}
            self.all_sequence_methods = set()
            self.aggregated_query_methods = {}

            # Repository íŒŒì¼ ìƒì„±
            logging.info(f"ğŸ’¾ Repository íŒŒì¼ ìƒì„± ì¤‘...")
            repository_list = await self._generate_repositories(table_dml_results)
            
            logging.info("\n" + "-"*80)
            logging.info(f"âœ… STEP 2 ì™„ë£Œ: {len(repository_list)}ê°œ Repository ìƒì„± ì™„ë£Œ")
            logging.info(f"   - JPA ì¿¼ë¦¬ ë©”ì„œë“œ: {len(self.all_used_query_methods)}ê°œ")
            logging.info(f"   - ì‹œí€€ìŠ¤ ë©”ì„œë“œ: {len(self.all_sequence_methods)}ê°œ")
            logging.info("-"*80 + "\n")
            return self.all_used_query_methods, self.global_vars, list(self.all_sequence_methods), repository_list

        except Exception as e:
            logging.error(f"Repository Interface ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise ConvertingError(f"Repository Interface ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        finally:
            await connection.close()

    # ----- ë‚´ë¶€ ì²˜ë¦¬ ë©”ì„œë“œ -----

    async def _generate_repositories(self, table_dml_results: list) -> list:
        """
        í…Œì´ë¸”ë³„ë¡œ Repository ìƒì„±
        1. Skeleton ìƒì„±
        2. DMLì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ì„œë“œ ìƒì„±
        3. ë³‘í•©
        
        Args:
            table_dml_results: í…Œì´ë¸”ë³„ DML ë…¸ë“œ ê²°ê³¼
        
        Returns:
            list: ìƒì„±ëœ Repository ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for result in table_dml_results:
            if not (dml_nodes := result.get('dml_nodes')):
                continue
            
            table_node = result['t']
            table_name = table_node['name']
            entity_name = convert_to_pascal_case(table_name)
            camel_name = convert_to_camel_case(entity_name)
            repo_name = f"{entity_name}Repository"
            
            try:
                logging.info(f"   ğŸ“ {repo_name} ìƒì„± ì¤‘...")
                
                # 1ë‹¨ê³„: Skeleton ìƒì„±
                skeleton = await self._generate_skeleton(entity_name, camel_name, table_name)
                
                # 2ë‹¨ê³„: DMLì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ì„œë“œ ìƒì„±
                await self._process_dml_nodes_for_entity(entity_name, dml_nodes)
                
                # 3ë‹¨ê³„: Skeletonê³¼ ë©”ì„œë“œ ë³‘í•©
                merged_methods = self.aggregated_query_methods.get(entity_name, [])
                if merged_methods:
                    methods_code = '\n\n'.join(
                        textwrap.indent(m.strip(), '    ') for m in merged_methods
                    )
                    # Skeletonì˜ CodePlaceHolderë¥¼ ë©”ì„œë“œë¡œ ì¹˜í™˜
                    code = skeleton.replace('CodePlaceHolder', methods_code)
                else:
                    code = skeleton
                
                # íŒŒì¼ ì €ì¥
                await save_file(code, f"{repo_name}.java", self.save_path)
                results.append({"repositoryName": repo_name, "code": code})
                logging.info(f"   âœ“ {repo_name} ìƒì„± ì™„ë£Œ")
                
            except Exception as e:
                logging.error(f"Entity '{entity_name}' Repository ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        return results

    async def _generate_skeleton(self, entity_name: str, camel_name: str, table_name: str) -> str:
        """
        Repository Skeleton (ê¸°ë³¸ í‹€) ìƒì„±
        
        Args:
            entity_name: Entity í´ë˜ìŠ¤ëª…
            camel_name: Entity camelCaseëª…
            table_name: ì›ë³¸ í…Œì´ë¸”ëª…
        
        Returns:
            str: Skeleton ì½”ë“œ
        """
        skeleton_data = self.rule_loader.execute(
            role_name='repository_skeleton',
            inputs={
                'entity_name': entity_name,
                'entity_camel_name': camel_name,
                'table_name': table_name,
                'project_name': self.project_name,
                'locale': self.locale
            },
            api_key=self.api_key
        )
        
        return skeleton_data.get('code', '')

    async def _process_dml_nodes_for_entity(self, entity_name: str, dml_nodes: list) -> None:
        """
        Entityì˜ DML ë…¸ë“œë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        
        Args:
            entity_name: Entity í´ë˜ìŠ¤ëª…
            dml_nodes: DML ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        """
        current_tokens = 0
        batch_codes = []
        batch_vars = defaultdict(list)

        for node in dml_nodes:
            # í•„ìˆ˜ í•„ë“œ ì²´í¬
            if 'token' not in node or 'startLine' not in node:
                continue
            
            # DML ì½”ë“œ ì¶”ì¶œ
            code = node.get('summarized_code') or node.get('node_code', '')
            
            # ê´€ë ¨ ë³€ìˆ˜ ì¶”ì¶œ
            var_nodes, var_tokens = await extract_used_variable_nodes(node['startLine'], self.var_index)
            total = current_tokens + node['token'] + var_tokens

            # ë°°ì¹˜ í† í° í•œë„ ì´ˆê³¼ ì‹œ ì¦‰ì‹œ ì²˜ë¦¬
            if batch_codes and total >= MAX_TOKENS:
                await self._flush_batch(entity_name, batch_codes, batch_vars)
                batch_codes, batch_vars, current_tokens = [], defaultdict(list), 0

            # ë°°ì¹˜ì— ì¶”ê°€
            batch_codes.append(code)
            for k, v in var_nodes.items():
                batch_vars[k].extend(v)
            current_tokens = total

        # ë§ˆì§€ë§‰ ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
        if batch_codes:
            await self._flush_batch(entity_name, batch_codes, batch_vars)

    async def _flush_batch(self, entity_name: str, codes: list, vars_dict: dict) -> None:
        """
        ë°°ì¹˜ë¥¼ LLMìœ¼ë¡œ ë³€í™˜í•˜ê³  ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ ì†ì„±ì— ì¦‰ì‹œ ëˆ„ì 
        
        Args:
            entity_name: Entity í´ë˜ìŠ¤ëª…
            codes: DML ì½”ë“œ ë¦¬ìŠ¤íŠ¸
            vars_dict: ë³€ìˆ˜ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        # Role íŒŒì¼ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰
        analysis_data = self.rule_loader.execute(
            role_name='repository',
            inputs={
                'entity_name': entity_name,
                'repository_nodes': json.dumps(codes, ensure_ascii=False, indent=2),
                'used_variable_nodes': json.dumps(vars_dict, ensure_ascii=False, indent=2),
                'count': len(codes),
                'global_variable_nodes': json.dumps(self.global_vars, ensure_ascii=False, indent=2),
                'locale': self.locale
            },
            api_key=self.api_key
        )
        
        # ë©”ì„œë“œë¥¼ Entityë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ëˆ„ì 
        for method in analysis_data.get('analysis', []):
            method_code = method['method']
            
            self.aggregated_query_methods.setdefault(entity_name, []).append(method_code)
            
            # ë¼ì¸ ë²”ìœ„ë³„ ë©”ì„œë“œ ë§¤í•‘
            for r in method.get('range', []):
                self.all_used_query_methods[f"{r['startLine']}~{r['endLine']}"] = method_code
        
        # ì‹œí€€ìŠ¤ ë©”ì„œë“œ ëˆ„ì 
        if seq := analysis_data.get('seq_method'):
            self.all_sequence_methods.update(seq)
